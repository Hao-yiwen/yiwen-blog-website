---
title: LLM 推理技术详解：KV Cache 标准机制
sidebar_label: KV Cache 推理机制
date: 2025-12-06
last_update:
  date: 2025-12-06
tags: [transformer, kv-cache, llm, inference, prefill, decode]
---

# LLM 推理技术详解：标准机制与工业级优化

**版本：** 2.0 (修订版)
**核心修订：** 明确区分了"KV Cache 的标准推理逻辑"与"工业级系统优化"。

---

## 1. 核心机制：KV Cache 标准推理流程

只要开启了 KV Cache（这是所有现代推理引擎的默认基准），LLM 的推理过程就**严格包含**两个截然不同的阶段：**Prefill（预填充）** 和 **Decode（解码）**。

这是算法层面的标准行为，旨在消除重复计算。

### 第一阶段：Prefill (预填充 / 首词生成)
**"一口气读完 Prompt，并生成第一个词"**

* **输入 (Input):** 完整的提示词序列 `[Token_0, Token_1, ..., Token_N-1]`。
* **计算行为:**
    * **全量计算：** 这是一个巨大的矩阵乘法。模型并行计算所有 Token 的 $Q, K, V$。
    * **填充 Cache：** 将计算出的所有 $K$ 和 $V$ 存入显存。
    * **首词预测：** 利用最后一个 Token 的输出，预测生成 `Token_N`。
* **算力特征:** **计算密集型 (Compute-bound)**。GPU 利用率极高，因为是一次性并行处理矩阵。

### 第二阶段：Decode (解码 / 自回归生成)
**"只进一个词，只算一次注意力"**

* **输入 (Input):** **仅仅是** 上一步生成的最新 Token `[Token_N]` (Shape: `1 × Dim`)。
    * *注意：这里绝对不会再输入之前的 Prompt。*
* **计算行为:**
    1.  **算当前:** 计算这 **1 个** Token 的 $Q_{new}, K_{new}, V_{new}$。
    2.  **取历史:** 从显存中取出之前存好的 $K_{cache}, V_{cache}$。
    3.  **拼整体:** $K_{all} = \text{Concat}(K_{cache}, K_{new})$。
    4.  **算 Attention:**
        * 使用 $Q_{new}$ (1个向量) 去查询 $K_{all}$ (N+1个向量)。
        * 运算本质是 **向量-矩阵乘法 (GEMV)**，而不是矩阵-矩阵乘法 (GEMM)。
* **算力特征:** **访存密集型 (Memory-bound)**。
    * 计算量非常小（只算一个词）。
    * 瓶颈在于**显存带宽**：需要把巨大的 $K_{cache}, V_{cache}$ 从显存搬运到计算核心，仅为了和这 1 个向量做乘法。

---

## 2. 为什么说这是"标准"而非"进阶"？

如下表所示，只要不是教学用的 Demo 代码，生产环境下的推理**必须**遵循上述逻辑。

| 模式 | 输入数据形状 (Step N) | Q 的计算量 | 是否可用 |
| :--- | :--- | :--- | :--- |
| **朴素模式** (NanoGPT) | `[0 ... N]` (全量) | 计算 $N$ 个 Q | ❌ **不可用** (速度 $O(N^2)$，慢且贵) |
| **标准 KV 模式** (HuggingFace) | **`[N]` (仅当前词)** | **计算 1 个 Q** | ✅ **基准线** (速度 $O(N)$，业界标准) |


## 3. 总结对比图

| 维度 | **NanoGPT (教学)** | **标准推理 (Baseline)** |
| :--- | :--- | :--- |
| **核心逻辑** | 每次重算全文 | **Prefill + Decode** |
| **Input 形状** | 变长 `[0...t]` | 恒定 `[1]` |
| **KV Cache** | 无 | 有 (连续显存) |
| **瓶颈** | 计算量爆炸 | 显存碎片 / 带宽瓶颈 |
| **代表库** | `minGPT` | `transformers` |

---

**一句话总结：**
**Prefill 和 Decode 是 KV Cache 的物理定律（基本逻辑）**
