---
title: 深度学习中的迁移学习、微调与 PEFT
sidebar_position: 20
tags: [迁移学习, 微调, PEFT, LoRA, CPT]
---

# 📘 深度学习中的迁移学习、微调与 PEFT —— 概念统一小文档

## 1. 迁移学习（Transfer Learning）

迁移学习是一种 **从任务 A 迁移知识到任务 B 的总体方法**。
核心思想：复用预训练模型,而不是从零训练。

典型形式：

-   冻结 Backbone,仅训练新的分类头（CV 常用）
-   加上任务特定模块,只训练小部分参数
-   对预训练模型整体再训练一段（微调）

迁移学习适用于 CNN（如 ResNet50）和 Transformer（如 BERT、GPT、Qwen）。

> **迁移学习 = 总体思想 / 大框架**

---

## 2. 微调（Fine-Tuning）

微调 = **对预训练模型进行少量再训练,使其适配新任务。**

形式包含：

-   **全参微调（Full FT）**：所有参数都更新
-   **部分微调（Partial FT）**：只更新某些层
-   **参数高效微调（PEFT）**：只更新少量新增模块（如 LoRA）

微调本质上是迁移学习的一种实现方式。

> **微调 ⊂ 迁移学习**

---

## 3. CNN 也能迁移学习 / 微调,不是 Transformer 专属

ResNet50 等 CNN 是迁移学习最早的应用场景：

-   冻结卷积层 → 训练 fc（特征抽取）
-   解冻 layer4 → 部分微调
-   全部解冻 → 全参微调
-   甚至可以插入 LoRA/Adapter（虽然不常用）

Transformer 只是让微调技术更系统化和普及。

---

## 4. 什么是 PEFT？（参数高效微调）

PEFT,全称 **Parameter-Efficient Fine-Tuning**,意思是：

> **不更新原模型参数,只训练极少新增参数即可完成任务适配。**

代表方法：

-   **LoRA（Low-Rank Adaptation,低秩调整）**
-   **Adapter（适配器层）**
-   **Prefix-tuning / P-tuning**
-   **BitFit（只训练 bias）**

PEFT 的优点：

-   显存占用极低
-   更新参数 < 1%
-   不破坏原模型能力
-   易于管理多个任务（多 LoRA 并存）

---

## 5. LoRA 名字的含义

LoRA = **Low-Rank Adaptation**

思想：

> 模型权重更新矩阵是低秩的,用一个小的低秩分解替代全量更新。

数学形式：

$$
\Delta W = BA
$$

其中 rank r 很小（如 4、8）,因此参数极少。

名字来源：

-   **Lo** = Low
-   **R** = Rank
-   **A** = Adaptation（适配）

---

## 6. PEFT 与部分微调（Partial FT）的关系

两者都属于 "只更新少量参数" 的微调范畴,但技术方式不同：

### 传统的 Partial FT

-   解冻某几层
-   直接更新原模型参数

### PEFT

-   原模型参数完全不动
-   只训练新增的 LoRA/Adapter/Prefix 模块

关系：

> **PEFT 是"部分参数微调"的更现代、更高效的实现方式。**
> 但 PEFT 不等于传统意义上的"解冻部分层"。

---

## 7. 📌 迁移学习体系：从零训练到继续预训练

迁移学习可以分成几个层级：

### ① 不训练参数

-   **Prompt engineering**：通过设计提示词引导模型输出
-   **Feature extraction**：冻结模型,仅用作特征提取器
-   **Linear probe**：冻结主体,只训练线性分类头

### ② 轻量训练（PEFT）

-   **LoRA** / **Adapter** / **Prefix tuning**
-   参数量 < 1%,显存占用极低
-   适合多任务并行,不破坏原模型

### ③ 部分参数微调

-   **解冻部分层**：如只更新最后几层
-   **LayerNorm-only FT**：只训练 LayerNorm 参数
-   **Head-only FT**：只训练任务头

### ④ 全参数微调（SFT - Supervised Fine-Tuning）

-   **更新全部参数**
-   在标注数据上训练
-   适配特定下游任务

### ⑤ 继续预训练（CPT / DAPT / TAPT）

这是迁移学习体系中最底层的阶段,发生在下游任务适配之前。

#### 什么是 CPT？

**CPT = Continual Pre-Training（继续预训练）**

**核心特点：**

-   使用**大量无标注数据**
-   保持**预训练目标**（如 MLM、CLM）
-   提升模型**底层语义与领域适配能力**
-   不针对特定任务,而是增强通用能力

#### CPT 的变体

1. **DAPT（Domain-Adaptive Pre-Training）**

    - 在特定领域数据上继续预训练
    - 例如：在医疗文本上继续训练 BERT
    - 目的：让模型适应该领域的语言特点

2. **TAPT（Task-Adaptive Pre-Training）**
    - 在任务相关的无标注数据上继续预训练
    - 例如：在情感分析的无标注评论上训练
    - 目的：让模型熟悉任务相关的数据分布

#### CPT 与 SFT 的区别

| 对比项   | CPT（继续预训练）        | SFT（监督微调）        |
| -------- | ------------------------ | ---------------------- |
| 数据     | 大量无标注数据           | 少量标注数据           |
| 训练目标 | MLM/CLM 等预训练目标     | 任务特定目标（分类等） |
| 目的     | 增强底层语义和领域适配   | 适配特定下游任务       |
| 时机     | 在下游任务微调之前       | 在 CPT 之后            |
| 示例     | 在医疗语料上继续训练 GPT | 在医疗问答数据集上微调 |

#### 典型流程

```
预训练（PT）
    ↓
继续预训练（CPT/DAPT/TAPT）
    ↓
监督微调（SFT）或 PEFT
    ↓
任务部署
```

---

## 8. 统一总结（记住这三句话）

### ① 迁移学习是思想

→ "从大模型 / 大数据集中迁移知识"。

### ② 微调是方法

→ "让预训练模型适应新任务"。

### ③ PEFT 是微调的升级版

→ "不改原模型,只训很小的模块,高效适配新任务"。

### ④ CPT 是预训练的延续

→ "在大量无标注数据上继续预训练,增强底层能力,为后续微调打基础"。

---

# 📌 一句话超级总结

> **迁移学习 = 框架**
> **微调 = 技术实现**
> **部分微调 = 更新部分层**
> **PEFT = 用少量新增参数微调（不改原模型）**
> **LoRA = 最常用的 PEFT（低秩增量）**
> **CPT = 在微调前的继续预训练（无标注数据,预训练目标）**
