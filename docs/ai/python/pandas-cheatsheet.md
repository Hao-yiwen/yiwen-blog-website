---
title: Pandas å¸¸ç”¨æ“ä½œé€ŸæŸ¥æ‰‹å†Œ
sidebar_label: Pandas é€ŸæŸ¥æ‰‹å†Œ
date: 2025-11-06
last_update:
  date: 2025-11-06
---

# Pandas å¸¸ç”¨æ“ä½œé€ŸæŸ¥æ‰‹å†Œ

## ğŸ“¦ å¯¼å…¥å’Œåˆ›å»º

```python
import pandas as pd
import numpy as np

# åˆ›å»º DataFrame
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': ['a', 'b', 'c', 'd'],
    'C': [1.1, 2.2, 3.3, 4.4]
})

# åˆ›å»º Series
s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])

# ä»å­—å…¸åˆ›å»º(æŒ‡å®šç´¢å¼•)
df = pd.DataFrame({
    'col1': [1, 2],
    'col2': [3, 4]
}, index=['row1', 'row2'])
```

---

## ğŸ“‚ æ•°æ®è¯»å–å’Œä¿å­˜

```python
# CSV æ–‡ä»¶
df = pd.read_csv('file.csv')
df = pd.read_csv('file.csv', encoding='utf-8')  # æŒ‡å®šç¼–ç 
df = pd.read_csv('file.csv', sep='\t')          # æŒ‡å®šåˆ†éš”ç¬¦
df.to_csv('output.csv', index=False)            # ä¿å­˜(ä¸ä¿å­˜ç´¢å¼•)

# Excel æ–‡ä»¶
df = pd.read_excel('file.xlsx', sheet_name='Sheet1')
df.to_excel('output.xlsx', index=False)

# JSON æ–‡ä»¶
df = pd.read_json('file.json')
df.to_json('output.json')

# SQL æ•°æ®åº“
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql('SELECT * FROM table', conn)
df.to_sql('table_name', conn, if_exists='replace')
```

---

## ğŸ‘€ æ•°æ®æŸ¥çœ‹

```python
# åŸºæœ¬ä¿¡æ¯
df.head()           # å‰5è¡Œ
df.head(10)         # å‰10è¡Œ
df.tail()           # å5è¡Œ
df.sample(5)        # éšæœº5è¡Œ

# æ•°æ®æ¦‚è§ˆ
df.shape            # (è¡Œæ•°, åˆ—æ•°)
df.info()           # æ•°æ®ç±»å‹ã€éç©ºå€¼æ•°é‡
df.describe()       # æ•°å€¼åˆ—çš„ç»Ÿè®¡æ‘˜è¦
df.dtypes           # æ¯åˆ—çš„æ•°æ®ç±»å‹
df.columns          # åˆ—å
df.index            # ç´¢å¼•

# ç»Ÿè®¡ä¿¡æ¯
df.count()          # éç©ºå€¼æ•°é‡
df.mean()           # å¹³å‡å€¼
df.median()         # ä¸­ä½æ•°
df.std()            # æ ‡å‡†å·®
df.min()            # æœ€å°å€¼
df.max()            # æœ€å¤§å€¼
df.sum()            # æ±‚å’Œ
df.value_counts()   # Series çš„å€¼è®¡æ•°
```

---

## ğŸ” æ•°æ®é€‰æ‹©å’Œç´¢å¼•

### é€‰æ‹©åˆ—

```python
df['A']                 # é€‰æ‹©å•åˆ—(è¿”å› Series)
df[['A', 'B']]          # é€‰æ‹©å¤šåˆ—(è¿”å› DataFrame)
df.A                    # é€šè¿‡å±æ€§è®¿é—®(ä¸æ¨èç”¨äºæœ‰ç©ºæ ¼çš„åˆ—å)
```

### é€‰æ‹©è¡Œ

```python
# åŸºäºä½ç½® - iloc
df.iloc[0]              # ç¬¬ä¸€è¡Œ
df.iloc[0:3]            # å‰3è¡Œ
df.iloc[[0, 2, 4]]      # ç‰¹å®šè¡Œ
df.iloc[:, 0:2]         # æ‰€æœ‰è¡Œ,å‰2åˆ—

# åŸºäºæ ‡ç­¾ - loc
df.loc[0]               # ç´¢å¼•ä¸º0çš„è¡Œ
df.loc[0:3]             # ç´¢å¼•0åˆ°3(åŒ…æ‹¬3)
df.loc[:, 'A':'C']      # æ‰€æœ‰è¡Œ,åˆ—Aåˆ°C
df.loc[df['A'] > 2]     # æ¡ä»¶ç­›é€‰
```

### æ¡ä»¶ç­›é€‰

```python
# å•æ¡ä»¶
df[df['A'] > 2]
df[df['B'] == 'a']

# å¤šæ¡ä»¶(ä¸)
df[(df['A'] > 2) & (df['B'] == 'a')]

# å¤šæ¡ä»¶(æˆ–)
df[(df['A'] > 2) | (df['B'] == 'a')]

# å–å
df[~(df['A'] > 2)]

# isin æ–¹æ³•
df[df['B'].isin(['a', 'b'])]

# å­—ç¬¦ä¸²åŒ…å«
df[df['B'].str.contains('a')]

# æŸ¥è¯¢è¯­æ³•(æ›´ç®€æ´)
df.query('A > 2 and B == "a"')
```

---

## ğŸ”§ æ•°æ®æ¸…æ´—

### ç¼ºå¤±å€¼å¤„ç†

```python
# æ£€æŸ¥ç¼ºå¤±å€¼
df.isnull()             # è¿”å›å¸ƒå°” DataFrame
df.isnull().sum()       # æ¯åˆ—ç¼ºå¤±å€¼æ•°é‡
df.isnull().any()       # æ¯åˆ—æ˜¯å¦æœ‰ç¼ºå¤±å€¼

# åˆ é™¤ç¼ºå¤±å€¼
df.dropna()             # åˆ é™¤ä»»ä½•åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
df.dropna(axis=1)       # åˆ é™¤ä»»ä½•åŒ…å«ç¼ºå¤±å€¼çš„åˆ—
df.dropna(how='all')    # åˆ é™¤å…¨ä¸ºç¼ºå¤±å€¼çš„è¡Œ
df.dropna(thresh=2)     # ä¿ç•™è‡³å°‘æœ‰2ä¸ªéç©ºå€¼çš„è¡Œ

# å¡«å……ç¼ºå¤±å€¼
df.fillna(0)            # ç”¨0å¡«å……
df.fillna(method='ffill')   # å‰å‘å¡«å……
df.fillna(method='bfill')   # åå‘å¡«å……
df['A'].fillna(df['A'].mean())  # ç”¨å¹³å‡å€¼å¡«å……
```

### é‡å¤å€¼å¤„ç†

```python
# æ£€æŸ¥é‡å¤
df.duplicated()         # è¿”å›å¸ƒå°” Series
df.duplicated().sum()   # é‡å¤è¡Œæ•°é‡

# åˆ é™¤é‡å¤
df.drop_duplicates()    # åˆ é™¤é‡å¤è¡Œ(ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°)
df.drop_duplicates(keep='last')     # ä¿ç•™æœ€åä¸€æ¬¡å‡ºç°
df.drop_duplicates(subset=['A'])    # åŸºäºç‰¹å®šåˆ—åˆ¤æ–­é‡å¤
```

### æ•°æ®ç±»å‹è½¬æ¢

```python
# è½¬æ¢å•åˆ—
df['A'] = df['A'].astype(int)
df['B'] = df['B'].astype(str)
df['C'] = pd.to_numeric(df['C'], errors='coerce')  # æ— æ³•è½¬æ¢çš„è®¾ä¸º NaN

# è½¬æ¢å¤šåˆ—
df = df.astype({'A': int, 'B': str})

# æ—¥æœŸæ—¶é—´è½¬æ¢
df['date'] = pd.to_datetime(df['date'])
```

---

## âœï¸ æ•°æ®ä¿®æ”¹

### æ·»åŠ /åˆ é™¤åˆ—

```python
# æ·»åŠ åˆ—
df['D'] = [5, 6, 7, 8]          # ç›´æ¥èµ‹å€¼
df['E'] = df['A'] + df['C']     # è®¡ç®—å¾—åˆ°
df.insert(1, 'F', [9, 10, 11, 12])  # åœ¨æŒ‡å®šä½ç½®æ’å…¥

# åˆ é™¤åˆ—
df.drop('D', axis=1, inplace=True)      # åˆ é™¤å•åˆ—
df.drop(['D', 'E'], axis=1, inplace=True)   # åˆ é™¤å¤šåˆ—
del df['F']                             # ç›´æ¥åˆ é™¤
```

### é‡å‘½å

```python
# é‡å‘½ååˆ—
df.rename(columns={'A': 'new_A', 'B': 'new_B'}, inplace=True)
df.columns = ['col1', 'col2', 'col3']   # é‡å‘½åæ‰€æœ‰åˆ—

# é‡å‘½åç´¢å¼•
df.rename(index={0: 'row1', 1: 'row2'}, inplace=True)
```

### ä¿®æ”¹å€¼

```python
# ä¿®æ”¹å•ä¸ªå€¼
df.loc[0, 'A'] = 100
df.iloc[0, 0] = 100

# ä¿®æ”¹æ•´åˆ—
df['A'] = 0
df['A'] = df['A'] * 2

# æ¡ä»¶ä¿®æ”¹
df.loc[df['A'] > 2, 'B'] = 'high'

# ä½¿ç”¨ replace
df['B'].replace('a', 'new_a', inplace=True)
df.replace({'a': 'new_a', 'b': 'new_b'}, inplace=True)
```

---

## ğŸ”„ æ•°æ®è½¬æ¢

### Apply å‡½æ•°

```python
# å¯¹åˆ—åº”ç”¨å‡½æ•°
df['A'].apply(lambda x: x * 2)
df['A'].apply(np.sqrt)

# å¯¹ DataFrame åº”ç”¨å‡½æ•°
df.apply(lambda x: x.max() - x.min())   # å¯¹æ¯åˆ—
df.apply(lambda x: x.max() - x.min(), axis=1)  # å¯¹æ¯è¡Œ

# map(ä»…ç”¨äº Series)
df['B'].map({'a': 1, 'b': 2, 'c': 3})

# applymap(å¯¹æ¯ä¸ªå…ƒç´ ) - å·²å¼ƒç”¨,ä½¿ç”¨ map
df[['A', 'C']].map(lambda x: x * 2)
```

### ç‹¬çƒ­ç¼–ç (One-Hot Encoding)

```python
# åŸºæœ¬ç”¨æ³• - å°†ç±»åˆ«å‹å˜é‡è½¬æ¢ä¸º 0/1 è™šæ‹Ÿå˜é‡
df = pd.DataFrame({
    'color': ['red', 'blue', 'green', 'red'],
    'size': ['S', 'M', 'L', 'M'],
    'price': [10, 20, 30, 15]
})

# å¯¹æ‰€æœ‰éæ•°å€¼åˆ—è‡ªåŠ¨ç¼–ç 
pd.get_dummies(df)
# ç»“æœ: price, color_blue, color_green, color_red, size_L, size_M, size_S

# åªå¯¹ç‰¹å®šåˆ—ç¼–ç 
pd.get_dummies(df, columns=['color'])

# æŒ‡å®šåˆ—åå‰ç¼€
pd.get_dummies(df, prefix={'color': 'é¢œè‰²', 'size': 'å°ºå¯¸'})

# åˆ é™¤ç¬¬ä¸€åˆ—(é¿å…å¤šé‡å…±çº¿æ€§,ç”¨äºçº¿æ€§å›å½’)
pd.get_dummies(df, drop_first=True)

# å¤„ç†ç¼ºå¤±å€¼
pd.get_dummies(df, dummy_na=True)

# å®é™…åº”ç”¨:è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸€è‡´æ€§ç¼–ç 
all_data = pd.concat([train_df, test_df])
all_encoded = pd.get_dummies(all_data, columns=['category_col'])
train_encoded = all_encoded[:len(train_df)]
test_encoded = all_encoded[len(train_df):]
```

### æ’åº

```python
# æŒ‰å€¼æ’åº
df.sort_values('A')                     # å‡åº
df.sort_values('A', ascending=False)    # é™åº
df.sort_values(['A', 'B'])              # å¤šåˆ—æ’åº
df.sort_values('A', inplace=True)       # åŸåœ°æ’åº

# æŒ‰ç´¢å¼•æ’åº
df.sort_index()
```

### åˆ†ç»„æ“ä½œ

```python
# åŸºæœ¬åˆ†ç»„
df.groupby('B').mean()          # æŒ‰Båˆ—åˆ†ç»„,è®¡ç®—å¹³å‡å€¼
df.groupby('B').sum()           # æ±‚å’Œ
df.groupby('B').count()         # è®¡æ•°
df.groupby('B').size()          # æ¯ç»„å¤§å°

# å¤šåˆ—åˆ†ç»„
df.groupby(['B', 'C']).mean()

# èšåˆå¤šä¸ªç»Ÿè®¡é‡
df.groupby('B').agg(['mean', 'sum', 'count'])

# å¯¹ä¸åŒåˆ—åº”ç”¨ä¸åŒèšåˆ
df.groupby('B').agg({
    'A': 'mean',
    'C': ['sum', 'max']
})

# è‡ªå®šä¹‰èšåˆå‡½æ•°
df.groupby('B').agg(lambda x: x.max() - x.min())
```

---

## ğŸ”— æ•°æ®åˆå¹¶

### Concat(æ‹¼æ¥)

```python
# å‚ç›´æ‹¼æ¥(è¡Œ)
pd.concat([df1, df2], axis=0)
pd.concat([df1, df2], ignore_index=True)  # é‡ç½®ç´¢å¼•

# æ°´å¹³æ‹¼æ¥(åˆ—)
pd.concat([df1, df2], axis=1)
```

### Merge(åˆå¹¶)

```python
# å†…è¿æ¥(é»˜è®¤)
pd.merge(df1, df2, on='key')

# å·¦è¿æ¥
pd.merge(df1, df2, on='key', how='left')

# å³è¿æ¥
pd.merge(df1, df2, on='key', how='right')

# å¤–è¿æ¥
pd.merge(df1, df2, on='key', how='outer')

# å¤šä¸ªé”®
pd.merge(df1, df2, on=['key1', 'key2'])

# ä¸åŒåˆ—åçš„é”®
pd.merge(df1, df2, left_on='key1', right_on='key2')
```

### Join(è¿æ¥)

```python
# åŸºäºç´¢å¼•è¿æ¥
df1.join(df2)
df1.join(df2, how='left')
df1.join(df2, lsuffix='_left', rsuffix='_right')  # å¤„ç†é‡å¤åˆ—å
```

---

## ğŸ“Š æ•°æ®é€è§†å’Œé‡å¡‘

### Pivot(é€è§†)

```python
# åˆ›å»ºé€è§†è¡¨
df.pivot(index='date', columns='category', values='value')

# é€è§†è¡¨(æ”¯æŒèšåˆ)
df.pivot_table(
    values='value',
    index='date',
    columns='category',
    aggfunc='mean'
)
```

### Melt(é€†é€è§†)

```python
# å®½æ ¼å¼è½¬é•¿æ ¼å¼
pd.melt(df, id_vars=['id'], value_vars=['A', 'B', 'C'])
```

### Stack/Unstack

```python
# Stack:åˆ—è½¬è¡Œ
df.stack()

# Unstack:è¡Œè½¬åˆ—
df.unstack()
```

---

## ğŸ“ˆ å­—ç¬¦ä¸²æ“ä½œ

```python
# å­—ç¬¦ä¸²æ–¹æ³•(éœ€è¦ .str è®¿é—®å™¨)
df['B'].str.upper()             # è½¬å¤§å†™
df['B'].str.lower()             # è½¬å°å†™
df['B'].str.strip()             # å»é™¤ç©ºæ ¼
df['B'].str.replace('a', 'A')   # æ›¿æ¢
df['B'].str.contains('a')       # æ˜¯å¦åŒ…å«
df['B'].str.startswith('a')     # æ˜¯å¦ä»¥...å¼€å¤´
df['B'].str.endswith('a')       # æ˜¯å¦ä»¥...ç»“å°¾
df['B'].str.split('_')          # åˆ†å‰²
df['B'].str.len()               # å­—ç¬¦ä¸²é•¿åº¦
df['B'].str[0]                  # å–ç¬¬ä¸€ä¸ªå­—ç¬¦
df['B'].str[:3]                 # åˆ‡ç‰‡
```

---

## ğŸ“… æ—¥æœŸæ—¶é—´æ“ä½œ

```python
# åˆ›å»ºæ—¥æœŸèŒƒå›´
dates = pd.date_range('2024-01-01', periods=10, freq='D')

# æ—¥æœŸæ—¶é—´å±æ€§
df['date'].dt.year              # å¹´
df['date'].dt.month             # æœˆ
df['date'].dt.day               # æ—¥
df['date'].dt.dayofweek         # æ˜ŸæœŸå‡ (0=å‘¨ä¸€)
df['date'].dt.hour              # å°æ—¶
df['date'].dt.minute            # åˆ†é’Ÿ

# æ—¥æœŸè®¡ç®—
df['date'] + pd.Timedelta(days=7)       # åŠ 7å¤©
df['date'] - pd.Timedelta(hours=2)      # å‡2å°æ—¶

# è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
df.set_index('date', inplace=True)

# æŒ‰æ—¶é—´ç­›é€‰
df['2024']                      # 2024å¹´çš„æ•°æ®
df['2024-01']                   # 2024å¹´1æœˆçš„æ•°æ®
```

---

## ğŸ¯ å®ç”¨æŠ€å·§

### é“¾å¼æ“ä½œ

```python
result = (df
    .dropna()
    .query('A > 2')
    .groupby('B')
    .mean()
    .sort_values('A', ascending=False)
)
```

### è®¾ç½®æ˜¾ç¤ºé€‰é¡¹

```python
pd.set_option('display.max_rows', 100)      # æœ€å¤§æ˜¾ç¤ºè¡Œæ•°
pd.set_option('display.max_columns', 20)    # æœ€å¤§æ˜¾ç¤ºåˆ—æ•°
pd.set_option('display.width', 1000)        # æ˜¾ç¤ºå®½åº¦
pd.set_option('display.precision', 2)       # å°æ•°ç²¾åº¦
pd.reset_option('all')                      # é‡ç½®æ‰€æœ‰é€‰é¡¹
```

### æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨åˆ†ç±»ç±»å‹èŠ‚çœå†…å­˜
df['B'] = df['B'].astype('category')

# è¯»å–å¤§æ–‡ä»¶æ—¶åˆ†å—
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process(chunk)

# ä½¿ç”¨ eval è¿›è¡Œå‘é‡åŒ–è®¡ç®—(æ›´å¿«)
df.eval('D = A + C', inplace=True)
```

---

## ğŸ’¡ å¸¸è§æ•°æ®æ¸…æ´—æµç¨‹

```python
# å®Œæ•´çš„æ•°æ®æ¸…æ´—ç¤ºä¾‹
df = (df
    .drop_duplicates()                          # åˆ é™¤é‡å¤
    .dropna(subset=['important_col'])           # åˆ é™¤å…³é”®åˆ—ç¼ºå¤±å€¼
    .fillna({'A': 0, 'B': 'unknown'})          # å¡«å……å…¶ä»–ç¼ºå¤±å€¼
    .assign(                                     # æ·»åŠ /ä¿®æ”¹åˆ—
        D=lambda x: x['A'] * 2,
        E=lambda x: x['B'].str.upper()
    )
    .query('A > 0')                             # ç­›é€‰
    .reset_index(drop=True)                     # é‡ç½®ç´¢å¼•
)

# æœºå™¨å­¦ä¹ é¢„å¤„ç†æµç¨‹
# 1. åˆ†ç¦»æ•°å€¼å’Œç±»åˆ«ç‰¹å¾
numeric_features = df.select_dtypes(include=[np.number]).columns
categorical_features = df.select_dtypes(include=['object']).columns

# 2. å¤„ç†æ•°å€¼ç‰¹å¾
df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())

# 3. å¤„ç†ç±»åˆ«ç‰¹å¾å¹¶ç¼–ç 
df[categorical_features] = df[categorical_features].fillna('missing')
df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)
```

---

## ğŸ” å¿«é€ŸæŸ¥æ‰¾å’Œç´¢å¼•

```python
# æŸ¥æ‰¾ç‰¹å®šå€¼çš„ä½ç½®
df[df['A'] == 5].index

# æŒ‰æ¡ä»¶è·å–ç¬¬ä¸€è¡Œ/æœ€åä¸€è¡Œ
df[df['A'] > 2].head(1)
df[df['A'] > 2].iloc[0]

# é‡ç½®ç´¢å¼•
df.reset_index(drop=True, inplace=True)

# è®¾ç½®ç´¢å¼•
df.set_index('A', inplace=True)

# å¤šçº§ç´¢å¼•
df.set_index(['A', 'B'], inplace=True)
```

---

## ğŸ“ å°æŠ„é€ŸæŸ¥

```python
# æœ€å¸¸ç”¨çš„æ“ä½œ
df.head()                       # æŸ¥çœ‹å‰å‡ è¡Œ
df.info()                       # æ•°æ®æ¦‚è§ˆ
df.describe()                   # ç»Ÿè®¡æ‘˜è¦
df[df['col'] > 5]              # æ¡ä»¶ç­›é€‰
df.groupby('col').mean()       # åˆ†ç»„èšåˆ
df.sort_values('col')          # æ’åº
df.dropna()                    # åˆ é™¤ç¼ºå¤±å€¼
df.fillna(0)                   # å¡«å……ç¼ºå¤±å€¼
pd.get_dummies(df)             # ç‹¬çƒ­ç¼–ç (ç±»åˆ«å˜é‡è½¬æ•°å€¼)
pd.merge(df1, df2, on='key')   # åˆå¹¶
df.to_csv('file.csv')          # ä¿å­˜
```

---

**è¿™ä»½é€ŸæŸ¥æ‰‹å†Œæ¶µç›–äº† pandas 95% çš„æ—¥å¸¸ä½¿ç”¨åœºæ™¯,å»ºè®®æ”¶è—!** ğŸ“š

---

*å‚è€ƒèµ„æº:*
- [Pandas å®˜æ–¹æ–‡æ¡£](https://pandas.pydata.org/docs/)
- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)
