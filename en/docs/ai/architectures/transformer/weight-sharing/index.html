<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ai/architectures/transformer/weight-sharing" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Weight Sharing (权重共享) | yiwen</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-test-site.com/yiwen-blog-website/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-test-site.com/yiwen-blog-website/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Weight Sharing (权重共享) | yiwen"><meta data-rh="true" name="description" content="1. 概述 (Overview)"><meta data-rh="true" property="og:description" content="1. 概述 (Overview)"><link data-rh="true" rel="icon" href="/yiwen-blog-website/en/img/logo.png"><link data-rh="true" rel="canonical" href="https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/yiwen-blog-website/docs/ai/architectures/transformer/weight-sharing" hreflang="zh"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/yiwen-blog-website/docs/ai/architectures/transformer/weight-sharing" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"模型架构","item":"https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/category/模型架构"},{"@type":"ListItem","position":2,"name":"Transformer","item":"https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/category/transformer"},{"@type":"ListItem","position":3,"name":"Weight Sharing 权重共享","item":"https://your-docusaurus-test-site.com/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing"}]}</script><link rel="alternate" type="application/rss+xml" href="/yiwen-blog-website/en/blog/rss.xml" title="yiwen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/yiwen-blog-website/en/blog/atom.xml" title="yiwen Atom Feed">






<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"><link rel="stylesheet" href="/yiwen-blog-website/en/assets/css/styles.d2356fea.css">
<script src="/yiwen-blog-website/en/assets/js/runtime~main.0111cdf8.js" defer="defer"></script>
<script src="/yiwen-blog-website/en/assets/js/main.a79fb3bb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/yiwen-blog-website/en/"><div class="navbar__logo"><img src="/yiwen-blog-website/en/img/logo.png" alt="yiwen&#x27;s blog" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/yiwen-blog-website/en/img/logo.png" alt="yiwen&#x27;s blog" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Yiwen</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/yiwen-blog-website/en/docs/category/深度学习基础">人工智能</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/backend/intro">服务端开发</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/category/android">Native开发</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/web/intro">Web开发</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/cs_base/intro">计算机基础</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/math/probability/">数学</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/docs/whelk/intro">抗痘</a><a class="navbar__item navbar__link" href="/yiwen-blog-website/en/blog">博客</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/yiwen-blog-website/docs/ai/architectures/transformer/weight-sharing" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh">中文</a></li></ul></div><a href="https://github.com/Hao-yiwen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/深度学习基础"><span title="深度学习基础" class="categoryLinkLabel_W154">深度学习基础</span></a><button aria-label="Collapse sidebar category &#x27;深度学习基础&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/数学基础"><span title="数学基础" class="categoryLinkLabel_W154">数学基础</span></a><button aria-label="Collapse sidebar category &#x27;数学基础&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/math/math-notation-guide"><span title="数学符号装饰指南" class="linkLabel_WmDU">数学符号装饰指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/math/Variance"><span title="方差 (Variance) 详解" class="linkLabel_WmDU">方差 (Variance) 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/math/norm"><span title="范数" class="linkLabel_WmDU">范数</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/math/qrthogonal"><span title="正交矩阵（Orthogonal）" class="linkLabel_WmDU">正交矩阵（Orthogonal）</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/训练核心概念"><span title="训练核心概念" class="categoryLinkLabel_W154">训练核心概念</span></a><button aria-label="Collapse sidebar category &#x27;训练核心概念&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/parameter-initialization-guide"><span title="参数初始化指南" class="linkLabel_WmDU">参数初始化指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/loss-functions"><span title="PyTorch Loss 函数详解" class="linkLabel_WmDU">PyTorch Loss 函数详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/K-FoldCrossValidation"><span title="K折交叉验证 (K-Fold Cross Validation)" class="linkLabel_WmDU">K折交叉验证 (K-Fold Cross Validation)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/accuracy_recall"><span title="准确率和召回率" class="linkLabel_WmDU">准确率和召回率</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/autograd-mechanism"><span title="自动微分机制" class="linkLabel_WmDU">自动微分机制</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/backpropagation"><span title="反向传播算法" class="linkLabel_WmDU">反向传播算法</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/batch-normalization"><span title="Batch Normalization" class="linkLabel_WmDU">Batch Normalization</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/computational_graph"><span title="计算图" class="linkLabel_WmDU">计算图</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/forwardpropagation"><span title="正向传播" class="linkLabel_WmDU">正向传播</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/linear-regression-backprop"><span title="线性回归反向传播推导" class="linkLabel_WmDU">线性回归反向传播推导</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/nll"><span title="概念文档：θ 与负对数似然 (NLL)" class="linkLabel_WmDU">概念文档：θ 与负对数似然 (NLL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/parameter-initialization"><span title="参数初始化" class="linkLabel_WmDU">参数初始化</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/relu_boom"><span title="梯度消失和爆炸问题" class="linkLabel_WmDU">梯度消失和爆炸问题</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/fundamentals/training/weight-init-vs-batch-norm"><span title="权重初始化 vs BN" class="linkLabel_WmDU">权重初始化 vs BN</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/优化器与训练技巧"><span title="优化器与训练技巧" class="categoryLinkLabel_W154">优化器与训练技巧</span></a><button aria-label="Collapse sidebar category &#x27;优化器与训练技巧&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/gradient-clipping"><span title="梯度裁剪（Gradient Clipping）" class="linkLabel_WmDU">梯度裁剪（Gradient Clipping）</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/gradient-descent-methods"><span title="梯度下降方法详解" class="linkLabel_WmDU">梯度下降方法详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/adam-optimizer"><span title="Adam 优化器详解" class="linkLabel_WmDU">Adam 优化器详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/adam-vs-adamw"><span title="Adam vs AdamW 深度对比" class="linkLabel_WmDU">Adam vs AdamW 深度对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/adam-vs-sgd"><span title="Adam vs SGD 优化器" class="linkLabel_WmDU">Adam vs SGD 优化器</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/learning-rate-schedulers"><span title="学习率调度器" class="linkLabel_WmDU">学习率调度器</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/momentum-explained"><span title="Momentum 动量算法详解" class="linkLabel_WmDU">Momentum 动量算法详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/optimization/weight_decy"><span title="权重衰减(Weight Decay)简介" class="linkLabel_WmDU">权重衰减(Weight Decay)简介</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/python"><span title="python" class="categoryLinkLabel_W154">python</span></a><button aria-label="Collapse sidebar category &#x27;python&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/matplotlib_intro"><span title="Matplotlib 入门" class="linkLabel_WmDU">Matplotlib 入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/vscode_debug_python"><span title="VS Code 中调试 Python 文件的简单指南" class="linkLabel_WmDU">VS Code 中调试 Python 文件的简单指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/base"><span title="python标准库" class="linkLabel_WmDU">python标准库</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/class"><span title="Python 类（Class）快速入门" class="linkLabel_WmDU">Python 类（Class）快速入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/common_problem"><span title="常见问题" class="linkLabel_WmDU">常见问题</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/conda"><span title="Conda 常用命令（简化版）" class="linkLabel_WmDU">Conda 常用命令（简化版）</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/dataclass"><span title="Dataclass 装饰器" class="linkLabel_WmDU">Dataclass 装饰器</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/decorarors"><span title="Python 装饰器简介" class="linkLabel_WmDU">Python 装饰器简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/fastapi"><span title="FastAPI 入门指南" class="linkLabel_WmDU">FastAPI 入门指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/lambda"><span title="Lambda 匿名函数" class="linkLabel_WmDU">Lambda 匿名函数</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/magic_methods"><span title="__call__ 方法" class="linkLabel_WmDU">__call__ 方法</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/matplotlib_inline"><span title="%matplotlib inline" class="linkLabel_WmDU">%matplotlib inline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/optional_pip"><span title="pip 可选依赖 [extras]" class="linkLabel_WmDU">pip 可选依赖 [extras]</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/pandas-cheatsheet"><span title="Pandas 速查手册" class="linkLabel_WmDU">Pandas 速查手册</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/pipx"><span title="pip vs pipx - 区别详解" class="linkLabel_WmDU">pip vs pipx - 区别详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/py_vs_js"><span title="Python vs JS 面向对象" class="linkLabel_WmDU">Python vs JS 面向对象</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/pyhonm"><span title="python -m 详解" class="linkLabel_WmDU">python -m 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/pypi"><span title="如何发布 PyPI 包 - 完整教程" class="linkLabel_WmDU">如何发布 PyPI 包 - 完整教程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/unpacking"><span title="解包" class="linkLabel_WmDU">解包</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/uv"><span title="uv 常用命令（简化版）" class="linkLabel_WmDU">uv 常用命令（简化版）</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/python/vscode_error"><span title="VSCode Notebook 导入报错解决指南" class="linkLabel_WmDU">VSCode Notebook 导入报错解决指南</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/yiwen-blog-website/en/docs/category/模型架构"><span title="模型架构" class="categoryLinkLabel_W154">模型架构</span></a><button aria-label="Collapse sidebar category &#x27;模型架构&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/cnn"><span title="CNN" class="categoryLinkLabel_W154">CNN</span></a><button aria-label="Collapse sidebar category &#x27;CNN&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/alexnet"><span title="AlexNet" class="linkLabel_WmDU">AlexNet</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/classic-networks"><span title="经典CNN架构" class="linkLabel_WmDU">经典CNN架构</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/convolution-basics"><span title="卷积基础原理" class="linkLabel_WmDU">卷积基础原理</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/googlenet-weight-initialization"><span title="GoogleNet 权重初始化" class="linkLabel_WmDU">GoogleNet 权重初始化</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/lenet"><span title="LeNet" class="linkLabel_WmDU">LeNet</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/nin-vgg-googlenet"><span title="NiN、VGG、GoogleNet" class="linkLabel_WmDU">NiN、VGG、GoogleNet</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/resnet"><span title="ResNet 残差网络详解" class="linkLabel_WmDU">ResNet 残差网络详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/ssd-yolov3-comparison"><span title="SSD vs YOLOv3 对比" class="linkLabel_WmDU">SSD vs YOLOv3 对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/cnn/yolo"><span title="yolo 目标检测" class="linkLabel_WmDU">yolo 目标检测</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/mlp"><span title="mlp" class="categoryLinkLabel_W154">mlp</span></a><button aria-label="Collapse sidebar category &#x27;mlp&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/mlp/dropout"><span title="Dropout 技术详解" class="linkLabel_WmDU">Dropout 技术详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/mlp/mlp-intro"><span title="多层感知机" class="linkLabel_WmDU">多层感知机</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/rnn"><span title="RNN" class="categoryLinkLabel_W154">RNN</span></a><button aria-label="Collapse sidebar category &#x27;RNN&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/rnn/rnn-from-scratch"><span title="RNN 从零实现" class="linkLabel_WmDU">RNN 从零实现</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/rnn/gru-from-scratch"><span title="GRU 从零实现" class="linkLabel_WmDU">GRU 从零实现</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/rnn/lstm-from-scratch"><span title="LSTM 从零实现" class="linkLabel_WmDU">LSTM 从零实现</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/yiwen-blog-website/en/docs/category/transformer"><span title="Transformer" class="categoryLinkLabel_W154">Transformer</span></a><button aria-label="Collapse sidebar category &#x27;Transformer&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/transformer_complete_implementation"><span title="Transformer 完整实现" class="linkLabel_WmDU">Transformer 完整实现</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/sft-training-guide"><span title="SFT 有监督微调训练指南" class="linkLabel_WmDU">SFT 有监督微调训练指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/dpo-training-guide"><span title="DPO 直接偏好优化训练指南" class="linkLabel_WmDU">DPO 直接偏好优化训练指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/engram-conditional-memory"><span title="Engram 条件记忆" class="linkLabel_WmDU">Engram 条件记忆</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/grpo-training-guide"><span title="GRPO 组相对策略优化详解" class="linkLabel_WmDU">GRPO 组相对策略优化详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/ppo-training-guide"><span title="PPO 近端策略优化训练指南" class="linkLabel_WmDU">PPO 近端策略优化训练指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/attention-mechanism-explained"><span title="注意力机制本质" class="linkLabel_WmDU">注意力机制本质</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/deepseek-v3-architecture"><span title="DeepSeek-V3.2 架构详解" class="linkLabel_WmDU">DeepSeek-V3.2 架构详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/flash-attention"><span title="FlashAttention" class="linkLabel_WmDU">FlashAttention</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/gpt2_simple"><span title="GPT-2 极简实现" class="linkLabel_WmDU">GPT-2 极简实现</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/gqa"><span title="GQA 分组查询注意力" class="linkLabel_WmDU">GQA 分组查询注意力</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/kv-cache"><span title="KV Cache 推理机制" class="linkLabel_WmDU">KV Cache 推理机制</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/ln-vs-bn-comparison"><span title="LN vs BN 对比" class="linkLabel_WmDU">LN vs BN 对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/mainstream_transformer"><span title="主流 Transformer 架构详解：GPT、BERT、T5" class="linkLabel_WmDU">主流 Transformer 架构详解：GPT、BERT、T5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/masked-self-attention"><span title="手写带掩码的自注意力机制" class="linkLabel_WmDU">手写带掩码的自注意力机制</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/paged-attention"><span title="PagedAttention" class="linkLabel_WmDU">PagedAttention</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/positional-encoding"><span title="绝对位置编码" class="linkLabel_WmDU">绝对位置编码</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/rmsnorm"><span title="RMSNorm 均方根归一化" class="linkLabel_WmDU">RMSNorm 均方根归一化</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/rope"><span title="RoPE 旋转位置编码" class="linkLabel_WmDU">RoPE 旋转位置编码</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/swiglu"><span title="SwiGLU 门控线性单元" class="linkLabel_WmDU">SwiGLU 门控线性单元</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/"><span title="Transformer基础架构" class="linkLabel_WmDU">Transformer基础架构</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/vision-transformer"><span title="Vision Transformer" class="linkLabel_WmDU">Vision Transformer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/weight-sharing"><span title="Weight Sharing 权重共享" class="linkLabel_WmDU">Weight Sharing 权重共享</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/yarn"><span title="YaRN 上下文扩展" class="linkLabel_WmDU">YaRN 上下文扩展</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/moe/moe-architecture"><span title="moe" class="categoryLinkLabel_W154">moe</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/architectures/moe/moe-architecture"><span title="MoE架构详解" class="linkLabel_WmDU">MoE架构详解</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/自然语言处理"><span title="自然语言处理" class="categoryLinkLabel_W154">自然语言处理</span></a><button aria-label="Collapse sidebar category &#x27;自然语言处理&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/n-gram"><span title="N-gram" class="linkLabel_WmDU">N-gram</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/markov-chain"><span title="马尔可夫链" class="linkLabel_WmDU">马尔可夫链</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/hmm"><span title="隐马尔可夫模型" class="linkLabel_WmDU">隐马尔可夫模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/chatml-special-tokens"><span title="ChatML 特殊标记" class="linkLabel_WmDU">ChatML 特殊标记</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/llm-emergence-grokking"><span title="LLM 涌现与顿悟" class="linkLabel_WmDU">LLM 涌现与顿悟</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/rag"><span title="RAG（检索增强生成）原理文档" class="linkLabel_WmDU">RAG（检索增强生成）原理文档</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/subword_tokenization"><span title="subword tokenization（子词分词器）" class="linkLabel_WmDU">subword tokenization（子词分词器）</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/tokenization-vs-embedding"><span title="分词与Embedding" class="linkLabel_WmDU">分词与Embedding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/why-bpe-is-mainstream"><span title="BPE 主流分词深度解析" class="linkLabel_WmDU">BPE 主流分词深度解析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/nlp/word2vec"><span title="Word2Vec" class="linkLabel_WmDU">Word2Vec</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/框架与工具"><span title="框架与工具" class="categoryLinkLabel_W154">框架与工具</span></a><button aria-label="Collapse sidebar category &#x27;框架与工具&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/工具与平台"><span title="工具与平台" class="categoryLinkLabel_W154">工具与平台</span></a><button aria-label="Collapse sidebar category &#x27;工具与平台&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/d2l-course"><span title="动手学深度学习" class="linkLabel_WmDU">动手学深度学习</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/nvidia-precision-formats"><span title="NVIDIA 数值格式" class="linkLabel_WmDU">NVIDIA 数值格式</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/nvidia-gpu-performance-comparison"><span title="GPU 算力对比" class="linkLabel_WmDU">GPU 算力对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/low-precision-formats"><span title="低精度格式对比" class="linkLabel_WmDU">低精度格式对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/fp8-training-explained"><span title="FP8 训练原理" class="linkLabel_WmDU">FP8 训练原理</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/arrow-parquet-formats"><span title="Arrow 与 Parquet 格式详解" class="linkLabel_WmDU">Arrow 与 Parquet 格式详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/gpu-monitoring"><span title="GPU 状态监控" class="linkLabel_WmDU">GPU 状态监控</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/autodl_presettings"><span title="AutoDL预设" class="linkLabel_WmDU">AutoDL预设</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/automl-autogluon"><span title="AutoML 与 AutoGluon 入门" class="linkLabel_WmDU">AutoML 与 AutoGluon 入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/hf-cli"><span title="HF CLI" class="linkLabel_WmDU">HF CLI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/hf-model-repo-structure"><span title="HF 模型仓库结构" class="linkLabel_WmDU">HF 模型仓库结构</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/hugging_face_transformers"><span title="Hugging Face Transformers" class="linkLabel_WmDU">Hugging Face Transformers</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/image_net"><span title="ImageNet 简介" class="linkLabel_WmDU">ImageNet 简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/iterm2"><span title="iTerm2 指南" class="linkLabel_WmDU">iTerm2 指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/jupyter"><span title="Jupyter Notebook 和 JupyterLab" class="linkLabel_WmDU">Jupyter Notebook 和 JupyterLab</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/kaggle-intro"><span title="Kaggle 入门" class="linkLabel_WmDU">Kaggle 入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/modelscope-cli"><span title="ModelScope CLI" class="linkLabel_WmDU">ModelScope CLI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/sklearn"><span title="Scikit-learn 实用工具指南" class="linkLabel_WmDU">Scikit-learn 实用工具指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/system-monitoring"><span title="btop 监控" class="linkLabel_WmDU">btop 监控</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/tmux"><span title="tmux 入门" class="linkLabel_WmDU">tmux 入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/tools/upload_proj"><span title="Hugging Face 模型上传完整教程（Git方式）" class="linkLabel_WmDU">Hugging Face 模型上传完整教程（Git方式）</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/pytorch"><span title="pytorch" class="categoryLinkLabel_W154">pytorch</span></a><button aria-label="Collapse sidebar category &#x27;pytorch&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/act_pytorch"><span title="激活函数" class="linkLabel_WmDU">激活函数</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/gelu_relu"><span title="深度解析：ReLU 与 GELU 的全面对比" class="linkLabel_WmDU">深度解析：ReLU 与 GELU 的全面对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/cat-vs-stack"><span title="PyTorch: cat vs stack 张量拼接" class="linkLabel_WmDU">PyTorch: cat vs stack 张量拼接</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/common-errors"><span title="PyTorch 常见错误与陷阱" class="linkLabel_WmDU">PyTorch 常见错误与陷阱</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/cpu-acceleration"><span title="CPU 加速效果" class="linkLabel_WmDU">CPU 加速效果</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/cpu_gpu_async"><span title="CPU-GPU 异步执行" class="linkLabel_WmDU">CPU-GPU 异步执行</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/file-formats"><span title="文件格式 (.pt/.pth/.safetensors)" class="linkLabel_WmDU">文件格式 (.pt/.pth/.safetensors)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/"><span title="PyTorch" class="linkLabel_WmDU">PyTorch</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/torch-compile"><span title="torch.compile" class="linkLabel_WmDU">torch.compile</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/frameworks/pytorch/view-reshape-contiguous"><span title="PyTorch: view vs reshape 与连续性" class="linkLabel_WmDU">PyTorch: view vs reshape 与连续性</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/部署与推理"><span title="部署与推理" class="categoryLinkLabel_W154">部署与推理</span></a><button aria-label="Collapse sidebar category &#x27;部署与推理&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/deployment/llm-serving-frameworks-comparison"><span title="vLLM vs TorchServe vs Triton：LLM 推理框架对比" class="linkLabel_WmDU">vLLM vs TorchServe vs Triton：LLM 推理框架对比</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/deployment/transfer-learning-peft"><span title="深度学习中的迁移学习、微调与 PEFT" class="linkLabel_WmDU">深度学习中的迁移学习、微调与 PEFT</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/deployment/scaling-law"><span title="大模型 Scaling Law 与后 Scaling Law 时代的应对策略" class="linkLabel_WmDU">大模型 Scaling Law 与后 Scaling Law 时代的应对策略</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/deployment/mainstream-dl-architectures"><span title="当前主流深度学习架构深度解析" class="linkLabel_WmDU">当前主流深度学习架构深度解析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/deployment/training-vs-inference-parallelism"><span title="训练vs推理并行性" class="linkLabel_WmDU">训练vs推理并行性</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/yiwen-blog-website/en/docs/category/应用场景"><span title="应用场景" class="categoryLinkLabel_W154">应用场景</span></a><button aria-label="Collapse sidebar category &#x27;应用场景&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/yiwen-blog-website/en/docs/category/推荐系统"><span title="推荐系统" class="categoryLinkLabel_W154">推荐系统</span></a><button aria-label="Collapse sidebar category &#x27;推荐系统&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/applications/recommendation/intro"><span title="推荐系统简介" class="linkLabel_WmDU">推荐系统简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/yiwen-blog-website/en/docs/ai/applications/recommendation/two-tower-model"><span title="双塔模型（Two-Tower）召回实现" class="linkLabel_WmDU">双塔模型（Two-Tower）召回实现</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/yiwen-blog-website/en/docs/ai/intro"><span title="人工智能" class="linkLabel_WmDU">人工智能</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/yiwen-blog-website/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/yiwen-blog-website/en/docs/category/模型架构"><span>模型架构</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/yiwen-blog-website/en/docs/category/transformer"><span>Transformer</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Weight Sharing 权重共享</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Weight Sharing (权重共享) 技术文档</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-概述-overview">1. 概述 (Overview)<a href="#1-概述-overview" class="hash-link" aria-label="Direct link to 1. 概述 (Overview)" title="Direct link to 1. 概述 (Overview)" translate="no">​</a></h2>
<p><strong>权重共享（Weight Tying/Sharing）</strong> 是现代语言模型中的一种重要优化技术，核心思想是：<strong>模型的输入层（Token Embedding）和输出层（Language Model Head）共用同一个权重矩阵。</strong></p>
<p>这一技术由 Press &amp; Wolf (2016) 在论文 <em>&quot;Using the Output Embedding to Improve Language Models&quot;</em> 中首次系统性提出，并被 GPT-2、GPT-3、LLaMA 等主流大语言模型广泛采用。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="核心价值">核心价值<a href="#核心价值" class="hash-link" aria-label="Direct link to 核心价值" title="Direct link to 核心价值" translate="no">​</a></h3>
<ul>
<li class=""><strong>减少参数量：</strong> 节省约 30-50% 的 Embedding 相关参数（对于大词表模型非常可观）。</li>
<li class=""><strong>提升模型效果：</strong> 通过强制语义对齐，实际上能降低困惑度（Perplexity）。</li>
<li class=""><strong>正则化效果：</strong> 减少过拟合风险，提升模型泛化能力。</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-工作原理-how-it-works">2. 工作原理 (How It Works)<a href="#2-工作原理-how-it-works" class="hash-link" aria-label="Direct link to 2. 工作原理 (How It Works)" title="Direct link to 2. 工作原理 (How It Works)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="21-代码实现">2.1 代码实现<a href="#21-代码实现" class="hash-link" aria-label="Direct link to 2.1 代码实现" title="Direct link to 2.1 代码实现" translate="no">​</a></h3>
<p>在 NanoGPT 的 <code>GPTLanguageModel</code> 类中，权重共享的实现非常简洁：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">GPTLanguageModel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 输入层：Token Embedding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> N_EMBED</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 输出层：Language Model Head</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">N_EMBED</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> bias</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 权重共享：Embedding 与 LM Head 共用同一权重矩阵</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="22-内存层面的理解">2.2 内存层面的理解<a href="#22-内存层面的理解" class="hash-link" aria-label="Direct link to 2.2 内存层面的理解" title="Direct link to 2.2 内存层面的理解" translate="no">​</a></h3>
<p>在 PyTorch 中，<code>nn.Parameter</code> 是对张量的封装。当执行 <code>self.lm_head.weight = self.token_embedding_table.weight</code> 时：</p>
<ul>
<li class=""><strong>物理存储：</strong> 内存中只存在 <strong>一份</strong> 形状为 <code>(vocab_size, N_EMBED)</code> 的张量。</li>
<li class=""><strong>逻辑层面：</strong>
<ul>
<li class=""><code>token_embedding_table</code> 将其视为 <strong>查找表（Look-up Table）</strong></li>
<li class=""><code>lm_head</code> 将其视为 <strong>线性变换矩阵（Linear Projection）</strong></li>
</ul>
</li>
<li class=""><strong>梯度更新：</strong> 反向传播时，同时累积来自输入端和输出端的梯度，更新时同步更新。</li>
</ul>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="23-维度匹配">2.3 维度匹配<a href="#23-维度匹配" class="hash-link" aria-label="Direct link to 2.3 维度匹配" title="Direct link to 2.3 维度匹配" translate="no">​</a></h3>
<p>你可能会疑惑 <code>nn.Embedding</code> 和 <code>nn.Linear</code> 的形状是否匹配：</p>
<table><thead><tr><th style="text-align:left">组件</th><th style="text-align:left">权重形状</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>nn.Embedding(V, D).weight</code></td><td style="text-align:left"><code>(V, D)</code></td><td style="text-align:left">词表大小 × 嵌入维度</td></tr><tr><td style="text-align:left"><code>nn.Linear(D, V).weight</code></td><td style="text-align:left"><code>(V, D)</code></td><td style="text-align:left">PyTorch 存储为 <code>(out_features, in_features)</code></td></tr></tbody></table>
<p>它们在内存中的形状 <strong>完全一致</strong>，可以直接赋值，无需转置操作。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-为什么要这样做">3. 为什么要这样做？<a href="#3-为什么要这样做" class="hash-link" aria-label="Direct link to 3. 为什么要这样做？" title="Direct link to 3. 为什么要这样做？" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="31-语义一致性-semantic-consistency">3.1 语义一致性 (Semantic Consistency)<a href="#31-语义一致性-semantic-consistency" class="hash-link" aria-label="Direct link to 3.1 语义一致性 (Semantic Consistency)" title="Direct link to 3.1 语义一致性 (Semantic Consistency)" translate="no">​</a></h3>
<p>这是权重共享最核心的理论依据：</p>
<ul>
<li class=""><strong>输入端：</strong> Embedding 层将 Token ID（如 &quot;Apple&quot;）转换为语义向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>a</mi><mi>p</mi><mi>p</mi><mi>l</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">v_{apple}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">ppl</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></li>
<li class=""><strong>输出端：</strong> LM Head 计算上下文向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span> 与词表中所有词的相似度（点积）</li>
</ul>
<p><strong>直觉理解：</strong> 如果模型在输入端认为向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span> 代表 &quot;Apple&quot;，那么在输出端，当模型想要预测 &quot;Apple&quot; 时，它生成的上下文向量应该 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span> 最相似。</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="32-减少参数量-parameter-efficiency">3.2 减少参数量 (Parameter Efficiency)<a href="#32-减少参数量-parameter-efficiency" class="hash-link" aria-label="Direct link to 3.2 减少参数量 (Parameter Efficiency)" title="Direct link to 3.2 减少参数量 (Parameter Efficiency)" translate="no">​</a></h3>
<p>这是最直接的工程优势。词汇表通常很大，Embedding 矩阵占用大量参数：</p>
<p><strong>参数量计算示例：</strong></p>
<table><thead><tr><th style="text-align:left">模型</th><th style="text-align:left">vocab_size</th><th style="text-align:left">N_EMBED</th><th style="text-align:left">单个矩阵参数量</th><th style="text-align:left">节省量</th></tr></thead><tbody><tr><td style="text-align:left">NanoGPT</td><td style="text-align:left">50,257</td><td style="text-align:left">768</td><td style="text-align:left">~38.6M</td><td style="text-align:left">~38.6M</td></tr><tr><td style="text-align:left">GPT-2</td><td style="text-align:left">50,257</td><td style="text-align:left">1,024</td><td style="text-align:left">~51.5M</td><td style="text-align:left">~51.5M</td></tr><tr><td style="text-align:left">LLaMA-7B</td><td style="text-align:left">32,000</td><td style="text-align:left">4,096</td><td style="text-align:left">~131M</td><td style="text-align:left">~131M (~500MB 显存)</td></tr><tr><td style="text-align:left">LLaMA-70B</td><td style="text-align:left">32,000</td><td style="text-align:left">8,192</td><td style="text-align:left">~262M</td><td style="text-align:left">~262M (~1GB  显存)</td></tr></tbody></table>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>节省参数量</mtext><mo>=</mo><mtext>vocab_size</mtext><mo>×</mo><mtext>N_EMBED</mtext></mrow><annotation encoding="application/x-tex">\text{节省参数量} = \text{vocab\_size} \times \text{N\_EMBED}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord text"><span class="mord cjk_fallback">节省参数量</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">vocab_size</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">N_EMBED</span></span></span></span></span></span>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="33-正则化效果-regularization">3.3 正则化效果 (Regularization)<a href="#33-正则化效果-regularization" class="hash-link" aria-label="Direct link to 3.3 正则化效果 (Regularization)" title="Direct link to 3.3 正则化效果 (Regularization)" translate="no">​</a></h3>
<p>参数量减少带来的额外好处：</p>
<ul>
<li class=""><strong>减少过拟合风险：</strong> 更少的参数意味着更少的过拟合机会</li>
<li class=""><strong>强制特征共享：</strong> 模型被迫学习一个既能表示输入特征，又能作为输出分类依据的 <strong>通用特征空间</strong></li>
<li class=""><strong>双向梯度更新：</strong> 共享权重同时接收来  自输入端和输出端的梯度，对低频词尤为有益</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-对模型效果的影响">4. 对模型效果的影响<a href="#4-对模型效果的影响" class="hash-link" aria-label="Direct link to 4. 对模型效果的影响" title="Direct link to 4. 对模型效果的影响" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="41-学术结论">4.1 学术结论<a href="#41-学术结论" class="hash-link" aria-label="Direct link to 4.1 学术结论" title="Direct link to 4.1 学术结论" translate="no">​</a></h3>
<p>根据 Press &amp; Wolf (2016) 及后续研究：</p>
<blockquote>
<p>在大多数语言建模任务中，权重共享 <strong>显著降低了困惑度（Perplexity）</strong>，即提升了预测准确率。</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="42-效果对比">4.2 效果对比<a href="#42-效果对比" class="hash-link" aria-label="Direct link to 4.2 效果对比" title="Direct link to 4.2 效果对比" translate="no">​</a></h3>
<table><thead><tr><th style="text-align:left">配置</th><th style="text-align:left">参数量</th><th style="text-align:left">困惑度 (PPL)</th><th style="text-align:left">训练稳定性</th></tr></thead><tbody><tr><td style="text-align:left">不共享权重</td><td style="text-align:left">基准</td><td style="text-align:left">基准</td><td style="text-align:left">一般</td></tr><tr><td style="text-align:left">共享权重</td><td style="text-align:left">↓ 显著减少</td><td style="text-align:left">↓ 通常更低</td><td style="text-align:left">↑ 更稳定</td></tr></tbody></table>
<img src="/yiwen-blog-website/en/assets/images/weight_share-66b720835d8a5b7a685e1d63b159a9a7.png" alt="权重共享训练稳定性对比">
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="43-为什么通常提升效果">4.3 为什么通常提升效果？<a href="#43-为什么通常提升效果" class="hash-link" aria-label="Direct link to 4.3 为什么通常提升效果？" title="Direct link to 4.3 为什么通常提升效果？" translate="no">​</a></h3>
<p><strong>A. 强制语义对齐（强正则化）</strong></p>
<ul>
<li class=""><strong>不共享时：</strong> 输入 Embedding 只需学习&quot;如何被后续层识别&quot;，输出 Linear 只需学习&quot;如何分类&quot;，可能学出两套完全不同的向量分布</li>
<li class=""><strong>共享时：</strong> 强制要求输入表示和输出预测目标位于同一几何空间</li>
</ul>
<p><strong>B. 训练效率更高</strong></p>
<ul>
<li class="">共享权重同时接收来自输入端和输出端的梯度信号</li>
<li class="">对 <strong>低频词（Rare Words）</strong> 尤为重要——双倍的梯度让它们被学习得更好</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-实现细节与注意事项">5. 实现细节与注意事项<a href="#5-实现细节与注意事项" class="hash-link" aria-label="Direct link to 5. 实现细节与注意事项" title="Direct link to 5. 实现细节与注意事项" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="51-必须设置-biasfalse">5.1 必须设置 <code>bias=False</code><a href="#51-必须设置-biasfalse" class="hash-link" aria-label="Direct link to 51-必须设置-biasfalse" title="Direct link to 51-必须设置-biasfalse" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">N_EMBED</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> bias</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># ✅ 正确</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">N_EMBED</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> bias</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">   </span><span class="token comment" style="color:#999988;font-style:italic"># ❌ 不推荐</span><br></span></code></pre></div></div>
<p><strong>原因：</strong> <code>nn.Embedding</code> 没有偏置项（Bias），如果 <code>lm_head</code> 带有 Bias，虽然权重矩阵可以共享，但 Bias 无法共享，导致逻辑不对称。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="52-缩放技巧-scaling">5.2 缩放技巧 (Scaling)<a href="#52-缩放技巧-scaling" class="hash-link" aria-label="Direct link to 5.2 缩放技巧 (Scaling)" title="Direct link to 5.2 缩放技巧 (Scaling)" translate="no">​</a></h3>
<p>在原始 Transformer 论文 <em>&quot;Attention Is All You Need&quot;</em> 中，Embedding 层输出后会乘以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_{model}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1828em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span></span>：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 原代码</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tok_emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">idx</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 改进：乘以 sqrt(d_model)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tok_emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">idx</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> math</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sqrt</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">N_EMBED</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><strong>为什么？</strong></p>
<ul>
<li class="">Embedding 权重初始化通常较小（方差约 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">1/d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1/</span><span class="mord mathnormal">d</span></span></span></span>）</li>
<li class="">经过多层 LayerNorm 和残差连接后，数值分布会变化</li>
<li class="">缩放可以使 Embedding 数值更适合进入后续 Attention 层，保持数值稳定性</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="53-初始化策略">5.3 初始化策略<a href="#53-初始化策略" class="hash-link" aria-label="Direct link to 5.3 初始化策略" title="Direct link to 5.3 初始化策略" translate="no">​</a></h3>
<p>由于权重被共享，初始化需要同时考虑两个用途：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 常见初始化方式</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">init</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">normal_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mean</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.02</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># lm_head.weight 自动共享，无需单独初始化</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-完整代码示例">6. 完整代码示例<a href="#6-完整代码示例" class="hash-link" aria-label="Direct link to 6. 完整代码示例" title="Direct link to 6. 完整代码示例" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="61-nanogpt-风格实现">6.1 NanoGPT 风格实现<a href="#61-nanogpt-风格实现" class="hash-link" aria-label="Direct link to 6.1 NanoGPT 风格实现" title="Direct link to 6.1 NanoGPT 风格实现" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> math</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">GPTLanguageModel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_embed</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_layer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_head</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> block_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dropout</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Token Embedding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_embed</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Position Embedding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">position_embedding_table </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">block_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_embed</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Transformer Blocks</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">blocks </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            TransformerBlock</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">n_embed</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_head</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> block_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dropout</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">n_layer</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Final LayerNorm</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ln_f </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">LayerNorm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">n_embed</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Language Model Head (输出层)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">n_embed</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> vocab_size</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> bias</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 🔑 权重共享：核心代码</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 初始化</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">apply</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">_init_weights</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">_init_weights</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">init</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">normal_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mean</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.02</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bias </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">init</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bias</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">init</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">normal_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">module</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mean</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> std</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.02</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">forward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> idx</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> targets</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        B</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> T </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> idx</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Token + Position Embedding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        tok_emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">idx</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (B, T, C)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pos_emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">position_embedding_table</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">arange</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">T</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> device</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">idx</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">device</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (T, C)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tok_emb </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> pos_emb  </span><span class="token comment" style="color:#999988;font-style:italic"># (B, T, C)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Transformer Blocks</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">blocks</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ln_f</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 输出 Logits</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        logits </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (B, T, vocab_size)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 计算 Loss</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> targets </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            B</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> T</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> C </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> logits</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            logits </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> logits</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">view</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">B</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">T</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> C</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            targets </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> targets</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">view</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">B</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">T</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cross_entropy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">logits</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> targets</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> logits</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> loss</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="62-验证权重确实共享">6.2 验证权重确实共享<a href="#62-验证权重确实共享" class="hash-link" aria-label="Direct link to 6.2 验证权重确实共享" title="Direct link to 6.2 验证权重确实共享" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> GPTLanguageModel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">vocab_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">50257</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_embed</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">768</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 验证两  者指向同一内存地址</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data_ptr</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data_ptr</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 输出相同的内存地址</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 验证两者是同一对象</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 输出: True</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="7-什么时候不共享可能更好">7. 什么时候不共享可能更好？<a href="#7-什么时候不共享可能更好" class="hash-link" aria-label="Direct link to 7. 什么时候不共享可能更好？" title="Direct link to 7. 什么时候不共享可能更好？" translate="no">​</a></h2>
<p>在极少数情况下，研究人员会选择解绑（Decouple）权重：</p>
<table><thead><tr><th style="text-align:left">场景</th><th style="text-align:left">原因</th></tr></thead><tbody><tr><td style="text-align:left"><strong>超大规模模型</strong></td><td style="text-align:left">数据和算力接近无限时，解绑可能让模型有更大自由度</td></tr><tr><td style="text-align:left"><strong>多语言/  特殊任务</strong></td><td style="text-align:left">输入和输出分布差异极大时</td></tr><tr><td style="text-align:left"><strong>编码器-解码器架构</strong></td><td style="text-align:left">某些 Seq2Seq 模型可能不适合共享</td></tr></tbody></table>
<p>但对于绝大多数场景（特别是 Decoder-only 的 GPT 架构），<strong>权重共享是标准做法</strong>。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="8-主流模型采用情况">8. 主流模型采用情况<a href="#8-主流模型采用情况" class="hash-link" aria-label="Direct link to 8. 主流模型采用情况" title="Direct link to 8. 主流模型采用情况" translate="no">​</a></h2>
<table><thead><tr><th style="text-align:left">模型</th><th style="text-align:left">是否使用权重共享</th><th style="text-align:left">备注</th></tr></thead><tbody><tr><td style="text-align:left">GPT-2</td><td style="text-align:left">✅ 是</td><td style="text-align:left">开创性采用</td></tr><tr><td style="text-align:left">GPT-3</td><td style="text-align:left">✅ 是</td><td style="text-align:left">沿用 GPT-2 设计</td></tr><tr><td style="text-align:left">LLaMA</td><td style="text-align:left">✅ 是</td><td style="text-align:left">明确在论文中说明</td></tr><tr><td style="text-align:left">LLaMA 2/3</td><td style="text-align:left">✅ 是</td><td style="text-align:left">继承 LLaMA 设计</td></tr><tr><td style="text-align:left">Mistral</td><td style="text-align:left">✅ 是</td><td style="text-align:left">业界标准做法</td></tr><tr><td style="text-align:left">BERT</td><td style="text-align:left">✅ 是</td><td style="text-align:left">在 MLM 任务中使用</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="9-常见问题-faq">9. 常见问题 (FAQ)<a href="#9-常见问题-faq" class="hash-link" aria-label="Direct link to 9. 常见问题 (FAQ)" title="Direct link to 9. 常见问题 (FAQ)" translate="no">​</a></h2>
<p><strong>Q: 权重共享会导致训练不稳定吗？</strong></p>
<p>A: 通常不会。相反，由于正则化效果，训练往往更稳定。如果遇到问题，可以尝试加入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_{model}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1828em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span></span> 缩放。</p>
<p><strong>Q: 我可以只在推理时解绑权重吗？</strong></p>
<p>A: 技术上可以（通过复制权重），但没有任何好处，反而会增加显存占用。</p>
<p><strong>Q: 共享权重对梯度计算有什么影响？</strong></p>
<p>A: 梯度会自动累积。PyTorch 的自动微分机制会正确处理共享参数的梯度，无需手动干预。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="10-总结">10. 总结<a href="#10-总结" class="hash-link" aria-label="Direct link to 10. 总结" title="Direct link to 10. 总结" translate="no">​</a></h2>
<table><thead><tr><th style="text-align:left">方面</th><th style="text-align:left">结论</th></tr></thead><tbody><tr><td style="text-align:left"><strong>是否推荐</strong></td><td style="text-align:left">✅ 强烈推荐（现代 LLM 标准做法）</td></tr><tr><td style="text-align:left"><strong>参数节省</strong></td><td style="text-align:left">vocab_size × N_EMBED（通常数千万参数）</td></tr><tr><td style="text-align:left"><strong>效果影响</strong></td><td style="text-align:left">通常 ↑ 提升（降低 PPL）</td></tr><tr><td style="text-align:left"><strong>实现复杂度</strong></td><td style="text-align:left">极低（一行代码）</td></tr></tbody></table>
<p><strong>核心代码：</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lm_head</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding_table</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-参考资料">11. 参考资料<a href="#11-参考资料" class="hash-link" aria-label="Direct link to 11. 参考资料" title="Direct link to 11. 参考资料" translate="no">​</a></h2>
<ul>
<li class=""><a href="https://arxiv.org/abs/1608.05859" target="_blank" rel="noopener noreferrer" class="">Using the Output Embedding to Improve Language Models</a> - Press &amp; Wolf, 2016（权重共享原始论文）</li>
<li class=""><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer" class="">Attention Is All You Need</a> - Vaswani et al., 2017</li>
<li class=""><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener noreferrer" class="">Language Models are Unsupervised Multitask Learners</a> - GPT-2 论文</li>
<li class=""><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="noopener noreferrer" class="">LLaMA: Open and Efficient Foundation Language Models</a> - Meta AI, 2023</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/transformer">transformer</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/embedding">embedding</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/lm-head">lm-head</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/weight-tying">weight-tying</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/parameter-efficiency">parameter-efficiency</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/yiwen-blog-website/en/docs/tags/regularization">regularization</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/Hao-yiwen/yiwen-blog-website/tree/master/docs/ai/architectures/transformer/weight-sharing.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-07T00:00:00.000Z" itemprop="dateModified">Dec 7, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/vision-transformer"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Vision Transformer</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/yiwen-blog-website/en/docs/ai/architectures/transformer/yarn"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">YaRN 上下文扩展</div></a></nav></div><div style="padding-top:50px"></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-概述-overview" class="table-of-contents__link toc-highlight">1. 概述 (Overview)</a><ul><li><a href="#核心价值" class="table-of-contents__link toc-highlight">核心价值</a></li></ul></li><li><a href="#2-工作原理-how-it-works" class="table-of-contents__link toc-highlight">2. 工作原理 (How It Works)</a><ul><li><a href="#21-代码实现" class="table-of-contents__link toc-highlight">2.1 代码实现</a></li><li><a href="#22-内存层面的理解" class="table-of-contents__link toc-highlight">2.2 内存层面的理解</a></li><li><a href="#23-维度匹配" class="table-of-contents__link toc-highlight">2.3 维度匹配</a></li></ul></li><li><a href="#3-为什么要这样做" class="table-of-contents__link toc-highlight">3. 为什么要这样做？</a><ul><li><a href="#31-语义一致性-semantic-consistency" class="table-of-contents__link toc-highlight">3.1 语义一致性 (Semantic Consistency)</a></li><li><a href="#32-减少参数量-parameter-efficiency" class="table-of-contents__link toc-highlight">3.2 减少参数量 (Parameter Efficiency)</a></li><li><a href="#33-正则化效果-regularization" class="table-of-contents__link toc-highlight">3.3 正则化效果 (Regularization)</a></li></ul></li><li><a href="#4-对模型效果的影响" class="table-of-contents__link toc-highlight">4. 对模型效果的影响</a><ul><li><a href="#41-学术结论" class="table-of-contents__link toc-highlight">4.1 学术结论</a></li><li><a href="#42-效果对比" class="table-of-contents__link toc-highlight">4.2 效果对比</a></li><li><a href="#43-为什么通常提升效果" class="table-of-contents__link toc-highlight">4.3 为什么通常提升效果？</a></li></ul></li><li><a href="#5-实现细节与注意事项" class="table-of-contents__link toc-highlight">5. 实现细节与注意事项</a><ul><li><a href="#51-必须设置-biasfalse" class="table-of-contents__link toc-highlight">5.1 必须设置 <code>bias=False</code></a></li><li><a href="#52-缩放技巧-scaling" class="table-of-contents__link toc-highlight">5.2 缩放技巧 (Scaling)</a></li><li><a href="#53-初始化策略" class="table-of-contents__link toc-highlight">5.3 初始化策略</a></li></ul></li><li><a href="#6-完整代码示例" class="table-of-contents__link toc-highlight">6. 完整代码示例</a><ul><li><a href="#61-nanogpt-风格实现" class="table-of-contents__link toc-highlight">6.1 NanoGPT 风格实现</a></li><li><a href="#62-验证权重确实共享" class="table-of-contents__link toc-highlight">6.2 验证权重确实共享</a></li></ul></li><li><a href="#7-什么时候不共享可能更好" class="table-of-contents__link toc-highlight">7. 什么时候不共享可能更好？</a></li><li><a href="#8-主流模型采用情况" class="table-of-contents__link toc-highlight">8. 主流模型采用情况</a></li><li><a href="#9-常见问题-faq" class="table-of-contents__link toc-highlight">9. 常见问题 (FAQ)</a></li><li><a href="#10-总结" class="table-of-contents__link toc-highlight">10. 总结</a></li><li><a href="#11-参考资料" class="table-of-contents__link toc-highlight">11. 参考资料</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>